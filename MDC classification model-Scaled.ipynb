{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "019e25c2",
   "metadata": {},
   "source": [
    "# PR Assignment -4 MDC classification model(with Scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c390a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d39a893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data from txt file into dataframe\n",
    "df = pd.read_csv(\"D:/ISIBangalore/MS-QMScourse/2nd sem/Pattern Recognition/Assignment-4/Vowel Data.txt\", sep = '\\s+', header=None, names=['class','x1','x2','x3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "567ef537",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,1:4] = (df.iloc[:,1:4] - df.iloc[:,1:4].min())/(df.iloc[:,1:4].max() - df.iloc[:,1:4].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49013072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping data classwise\n",
    "dflist = list(df.groupby('class'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ef009e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# segregating dataframe class wise\n",
    "df1 = dflist[0][1]\n",
    "df2 = dflist[1][1]\n",
    "df3 = dflist[2][1]\n",
    "df4 = dflist[3][1]\n",
    "df5 = dflist[4][1]\n",
    "df6 = dflist[5][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "448779a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# segregating input features and output feature for each class\n",
    "df1_x = df1.drop(columns=['class'])\n",
    "df1_y = df1.iloc[:,0]\n",
    "df2_x = df2.drop(columns=['class'])\n",
    "df2_y = df2.iloc[:,0]\n",
    "df3_x = df3.drop(columns=['class'])\n",
    "df3_y = df3.iloc[:,0]\n",
    "df4_x = df4.drop(columns=['class'])\n",
    "df4_y = df4.iloc[:,0]\n",
    "df5_x = df5.drop(columns=['class'])\n",
    "df5_y = df5.iloc[:,0]\n",
    "df6_x = df6.drop(columns=['class'])\n",
    "df6_y = df6.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f417de63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# splitting each data frame into training and test data\\ndf1_x_train, df1_x_test, df1_y_train, df1_y_test = train_test_split(df1_x, df1_y, test_size = testsize[i])\\ndf2_x_train, df2_x_test, df2_y_train, df2_y_test = train_test_split(df2_x, df2_y, test_size = testsize[i])\\ndf3_x_train, df3_x_test, df3_y_train, df3_y_test = train_test_split(df3_x, df3_y, test_size = testsize[i])\\ndf4_x_train, df4_x_test, df4_y_train, df4_y_test = train_test_split(df4_x, df4_y, test_size = testsize[i])\\ndf5_x_train, df5_x_test, df5_y_train, df5_y_test = train_test_split(df5_x, df5_y, test_size = testsize[i])\\ndf6_x_train, df6_x_test, df6_y_train, df6_y_test = train_test_split(df6_x, df6_y, test_size = testsize[i])\\n        \\nscaler1 = StandardScaler()\\nscaler1.fit(df1_x_train)\\ndf1_x_train = pd.DataFrame(scaler1.transform(df1_x_train))\\ndf1_x_test = pd.DataFrame(scaler1.transform(df1_x_test))\\nscaler2 = StandardScaler()\\nscaler2.fit(df2_x_train)\\ndf2_x_train = pd.DataFrame(scaler2.transform(df2_x_train))\\ndf2_x_test = pd.DataFrame(scaler2.transform(df2_x_test))\\nscaler3 = StandardScaler()\\nscaler3.fit(df3_x_train)\\ndf3_x_train = pd.DataFrame(scaler3.transform(df3_x_train))\\ndf3_x_test = pd.DataFrame(scaler3.transform(df3_x_test))\\nscaler4 = StandardScaler()\\nscaler4.fit(df4_x_train)\\ndf4_x_train = pd.DataFrame(scaler4.transform(df4_x_train))\\ndf4_x_test = pd.DataFrame(scaler4.transform(df4_x_test))\\nscaler5 = StandardScaler()\\nscaler5.fit(df5_x_train)\\ndf5_x_train = pd.DataFrame(scaler5.transform(df5_x_train))\\ndf5_x_test = pd.DataFrame(scaler5.transform(df5_x_test))\\nscaler6 = StandardScaler()\\nscaler6.fit(df6_x_train)\\ndf6_x_train = pd.DataFrame(scaler6.transform(df6_x_train))\\ndf6_x_test = pd.DataFrame(scaler6.transform(df6_x_test))\\n        \\n# combining training and test data from each class\\nx_train = pd.concat([df1_x_train, df2_x_train, df3_x_train, df4_x_train, df5_x_train, df6_x_train], axis=0)\\ny_train = pd.concat([df1_y_train, df2_y_train, df3_y_train, df4_y_train, df5_y_train, df6_y_train], axis=0)\\nx_test = pd.concat([df1_x_test, df2_x_test, df3_x_test, df4_x_test, df5_x_test, df6_x_test], axis=0)\\ny_test = pd.concat([df1_y_test, df2_y_test, df3_y_test, df4_y_test, df5_y_test, df6_y_test], axis=0)\\n\\nscaler1 = StandardScaler()\\nscaler1.fit(x_train)\\nx_train = pd.DataFrame(scaler1.transform(x_train))\\nx_test = pd.DataFrame(scaler1.transform(x_test))\\n\\n# centroid from training data of each class\\ncent1 = np.array(df1_x_train.mean())\\ncent2 = np.array(df2_x_train.mean())\\ncent3 = np.array(df3_x_train.mean())\\ncent4 = np.array(df4_x_train.mean())\\ncent5 = np.array(df5_x_train.mean())\\ncent6 = np.array(df6_x_train.mean())\\n# converting training & test input features dataframe to array form\\n#x_train_arr = x_train.to_numpy()\\nx_test_arr = x_test.to_numpy()\\n# predicting output class for training data\\ny_pred_train = []\\nfor k in range(x_train['x1'].count()):\\n    x = x_train_arr[k]\\n    d1 = np.linalg.norm(x - cent1)\\n    d2 = np.linalg.norm(x - cent2)\\n    d3 = np.linalg.norm(x - cent3)\\n    d4 = np.linalg.norm(x - cent4)\\n    d5 = np.linalg.norm(x - cent5)\\n    d6 = np.linalg.norm(x - cent6)\\n    d = [d1, d2, d3, d4, d5, d6]\\n    y_pred_train.append(d.index(min(d)) + 1)\\n    ypred_train = np.array(y_pred_train)\\n    acc_table_train = accuracy_score(y_train, ypred_train)\\n# predicting output class for test data\\ny_pred_test = []\\nfor k in range(x_test['x1'].count()):\\n    x = x_test_arr[k]\\n    d1 = np.linalg.norm(x - cent1)\\n    d2 = np.linalg.norm(x - cent2)\\n    d3 = np.linalg.norm(x - cent3)\\n    d4 = np.linalg.norm(x - cent4)\\n    d5 = np.linalg.norm(x - cent5)\\n    d6 = np.linalg.norm(x - cent6)\\n    d = [d1, d2, d3, d4, d5, d6]\\n    y_pred_test.append(d.index(min(d)) + 1)\\n    \\nypred_test = np.array(y_pred_test)\\nacc_table_test = accuracy_score(y_test, ypred_test)\\n#print(acc_table_train)\\nprint(acc_table_test)\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# splitting each data frame into training and test data\n",
    "df1_x_train, df1_x_test, df1_y_train, df1_y_test = train_test_split(df1_x, df1_y, test_size = testsize[i])\n",
    "df2_x_train, df2_x_test, df2_y_train, df2_y_test = train_test_split(df2_x, df2_y, test_size = testsize[i])\n",
    "df3_x_train, df3_x_test, df3_y_train, df3_y_test = train_test_split(df3_x, df3_y, test_size = testsize[i])\n",
    "df4_x_train, df4_x_test, df4_y_train, df4_y_test = train_test_split(df4_x, df4_y, test_size = testsize[i])\n",
    "df5_x_train, df5_x_test, df5_y_train, df5_y_test = train_test_split(df5_x, df5_y, test_size = testsize[i])\n",
    "df6_x_train, df6_x_test, df6_y_train, df6_y_test = train_test_split(df6_x, df6_y, test_size = testsize[i])\n",
    "        \n",
    "scaler1 = StandardScaler()\n",
    "scaler1.fit(df1_x_train)\n",
    "df1_x_train = pd.DataFrame(scaler1.transform(df1_x_train))\n",
    "df1_x_test = pd.DataFrame(scaler1.transform(df1_x_test))\n",
    "scaler2 = StandardScaler()\n",
    "scaler2.fit(df2_x_train)\n",
    "df2_x_train = pd.DataFrame(scaler2.transform(df2_x_train))\n",
    "df2_x_test = pd.DataFrame(scaler2.transform(df2_x_test))\n",
    "scaler3 = StandardScaler()\n",
    "scaler3.fit(df3_x_train)\n",
    "df3_x_train = pd.DataFrame(scaler3.transform(df3_x_train))\n",
    "df3_x_test = pd.DataFrame(scaler3.transform(df3_x_test))\n",
    "scaler4 = StandardScaler()\n",
    "scaler4.fit(df4_x_train)\n",
    "df4_x_train = pd.DataFrame(scaler4.transform(df4_x_train))\n",
    "df4_x_test = pd.DataFrame(scaler4.transform(df4_x_test))\n",
    "scaler5 = StandardScaler()\n",
    "scaler5.fit(df5_x_train)\n",
    "df5_x_train = pd.DataFrame(scaler5.transform(df5_x_train))\n",
    "df5_x_test = pd.DataFrame(scaler5.transform(df5_x_test))\n",
    "scaler6 = StandardScaler()\n",
    "scaler6.fit(df6_x_train)\n",
    "df6_x_train = pd.DataFrame(scaler6.transform(df6_x_train))\n",
    "df6_x_test = pd.DataFrame(scaler6.transform(df6_x_test))\n",
    "        \n",
    "# combining training and test data from each class\n",
    "x_train = pd.concat([df1_x_train, df2_x_train, df3_x_train, df4_x_train, df5_x_train, df6_x_train], axis=0)\n",
    "y_train = pd.concat([df1_y_train, df2_y_train, df3_y_train, df4_y_train, df5_y_train, df6_y_train], axis=0)\n",
    "x_test = pd.concat([df1_x_test, df2_x_test, df3_x_test, df4_x_test, df5_x_test, df6_x_test], axis=0)\n",
    "y_test = pd.concat([df1_y_test, df2_y_test, df3_y_test, df4_y_test, df5_y_test, df6_y_test], axis=0)\n",
    "\n",
    "scaler1 = StandardScaler()\n",
    "scaler1.fit(x_train)\n",
    "x_train = pd.DataFrame(scaler1.transform(x_train))\n",
    "x_test = pd.DataFrame(scaler1.transform(x_test))\n",
    "\n",
    "# centroid from training data of each class\n",
    "cent1 = np.array(df1_x_train.mean())\n",
    "cent2 = np.array(df2_x_train.mean())\n",
    "cent3 = np.array(df3_x_train.mean())\n",
    "cent4 = np.array(df4_x_train.mean())\n",
    "cent5 = np.array(df5_x_train.mean())\n",
    "cent6 = np.array(df6_x_train.mean())\n",
    "# converting training & test input features dataframe to array form\n",
    "#x_train_arr = x_train.to_numpy()\n",
    "x_test_arr = x_test.to_numpy()\n",
    "# predicting output class for training data\n",
    "y_pred_train = []\n",
    "for k in range(x_train['x1'].count()):\n",
    "    x = x_train_arr[k]\n",
    "    d1 = np.linalg.norm(x - cent1)\n",
    "    d2 = np.linalg.norm(x - cent2)\n",
    "    d3 = np.linalg.norm(x - cent3)\n",
    "    d4 = np.linalg.norm(x - cent4)\n",
    "    d5 = np.linalg.norm(x - cent5)\n",
    "    d6 = np.linalg.norm(x - cent6)\n",
    "    d = [d1, d2, d3, d4, d5, d6]\n",
    "    y_pred_train.append(d.index(min(d)) + 1)\n",
    "    ypred_train = np.array(y_pred_train)\n",
    "    acc_table_train = accuracy_score(y_train, ypred_train)\n",
    "# predicting output class for test data\n",
    "y_pred_test = []\n",
    "for k in range(x_test['x1'].count()):\n",
    "    x = x_test_arr[k]\n",
    "    d1 = np.linalg.norm(x - cent1)\n",
    "    d2 = np.linalg.norm(x - cent2)\n",
    "    d3 = np.linalg.norm(x - cent3)\n",
    "    d4 = np.linalg.norm(x - cent4)\n",
    "    d5 = np.linalg.norm(x - cent5)\n",
    "    d6 = np.linalg.norm(x - cent6)\n",
    "    d = [d1, d2, d3, d4, d5, d6]\n",
    "    y_pred_test.append(d.index(min(d)) + 1)\n",
    "    \n",
    "ypred_test = np.array(y_pred_test)\n",
    "acc_table_test = accuracy_score(y_test, ypred_test)\n",
    "#print(acc_table_train)\n",
    "print(acc_table_test)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f948fb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "testsize = [0.1, 0.2, 0.3, 0.4]\n",
    "acc_table_train = np.empty((4, 10))\n",
    "acc_table_test = np.empty((4, 10))\n",
    "for i in range(4):\n",
    "    for j in range(10):\n",
    "        # splitting each data frame into training and test data\n",
    "        df1_x_train, df1_x_test, df1_y_train, df1_y_test = train_test_split(df1_x, df1_y, test_size = testsize[i])\n",
    "        df2_x_train, df2_x_test, df2_y_train, df2_y_test = train_test_split(df2_x, df2_y, test_size = testsize[i])\n",
    "        df3_x_train, df3_x_test, df3_y_train, df3_y_test = train_test_split(df3_x, df3_y, test_size = testsize[i])\n",
    "        df4_x_train, df4_x_test, df4_y_train, df4_y_test = train_test_split(df4_x, df4_y, test_size = testsize[i])\n",
    "        df5_x_train, df5_x_test, df5_y_train, df5_y_test = train_test_split(df5_x, df5_y, test_size = testsize[i])\n",
    "        df6_x_train, df6_x_test, df6_y_train, df6_y_test = train_test_split(df6_x, df6_y, test_size = testsize[i])\n",
    "        # combining training and test data from each class\n",
    "        x_train = pd.concat([df1_x_train, df2_x_train, df3_x_train, df4_x_train, df5_x_train, df6_x_train], axis=0)\n",
    "        y_train = pd.concat([df1_y_train, df2_y_train, df3_y_train, df4_y_train, df5_y_train, df6_y_train], axis=0)\n",
    "        x_test = pd.concat([df1_x_test, df2_x_test, df3_x_test, df4_x_test, df5_x_test, df6_x_test], axis=0)\n",
    "        y_test = pd.concat([df1_y_test, df2_y_test, df3_y_test, df4_y_test, df5_y_test, df6_y_test], axis=0)\n",
    "        # centroid from training data of each class\n",
    "        cent1 = np.array(df1_x_train.mean())\n",
    "        cent2 = np.array(df2_x_train.mean())\n",
    "        cent3 = np.array(df3_x_train.mean())\n",
    "        cent4 = np.array(df4_x_train.mean())\n",
    "        cent5 = np.array(df5_x_train.mean())\n",
    "        cent6 = np.array(df6_x_train.mean())\n",
    "        # converting training & test input features dataframe to array form\n",
    "        x_train_arr = x_train.to_numpy()\n",
    "        x_test_arr = x_test.to_numpy()\n",
    "        # predicting output class for training data\n",
    "        y_pred_train = []\n",
    "        for k in range(x_train['x1'].count()):\n",
    "            x = x_train_arr[k]\n",
    "            d1 = np.linalg.norm(x - cent1)\n",
    "            d2 = np.linalg.norm(x - cent2)\n",
    "            d3 = np.linalg.norm(x - cent3)\n",
    "            d4 = np.linalg.norm(x - cent4)\n",
    "            d5 = np.linalg.norm(x - cent5)\n",
    "            d6 = np.linalg.norm(x - cent6)\n",
    "            d = [d1, d2, d3, d4, d5, d6]\n",
    "            y_pred_train.append(d.index(min(d)) + 1)\n",
    "        ypred_train = np.array(y_pred_train)\n",
    "        acc_table_train[i][j] = accuracy_score(y_train, ypred_train)\n",
    "        # predicting output class for test data\n",
    "        y_pred_test = []\n",
    "        for k in range(x_test['x1'].count()):\n",
    "            x = x_test_arr[k]\n",
    "            d1 = np.linalg.norm(x - cent1)\n",
    "            d2 = np.linalg.norm(x - cent2)\n",
    "            d3 = np.linalg.norm(x - cent3)\n",
    "            d4 = np.linalg.norm(x - cent4)\n",
    "            d5 = np.linalg.norm(x - cent5)\n",
    "            d6 = np.linalg.norm(x - cent6)\n",
    "            d = [d1, d2, d3, d4, d5, d6]\n",
    "            y_pred_test.append(d.index(min(d)) + 1)\n",
    "        ypred_test = np.array(y_pred_test)\n",
    "        acc_table_test[i][j] = accuracy_score(y_test, ypred_test)\n",
    "\n",
    "acc_table_train_df = pd.DataFrame(np.transpose(np.round(acc_table_train*100,2)), columns=['90-10', '80-20', '70-30', '60-40'], index=['1st','2nd','3rd','4th','5th','6th','7th','8th','9th','10th'])\n",
    "acc_table_test_df  = pd.DataFrame(np.transpose(np.round(acc_table_test*100, 2)), columns=['90-10', '80-20', '70-30', '60-40'], index=['1st','2nd','3rd','4th','5th','6th','7th','8th','9th','10th'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4432334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>90-10</th>\n",
       "      <th>80-20</th>\n",
       "      <th>70-30</th>\n",
       "      <th>60-40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1st</th>\n",
       "      <td>77.340</td>\n",
       "      <td>78.67</td>\n",
       "      <td>77.43</td>\n",
       "      <td>77.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2nd</th>\n",
       "      <td>77.210</td>\n",
       "      <td>77.52</td>\n",
       "      <td>77.59</td>\n",
       "      <td>78.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3rd</th>\n",
       "      <td>77.720</td>\n",
       "      <td>78.53</td>\n",
       "      <td>77.10</td>\n",
       "      <td>78.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4th</th>\n",
       "      <td>77.850</td>\n",
       "      <td>77.95</td>\n",
       "      <td>79.24</td>\n",
       "      <td>77.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5th</th>\n",
       "      <td>77.980</td>\n",
       "      <td>76.08</td>\n",
       "      <td>78.58</td>\n",
       "      <td>77.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6th</th>\n",
       "      <td>77.980</td>\n",
       "      <td>77.67</td>\n",
       "      <td>80.56</td>\n",
       "      <td>76.580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7th</th>\n",
       "      <td>77.340</td>\n",
       "      <td>76.37</td>\n",
       "      <td>78.25</td>\n",
       "      <td>80.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8th</th>\n",
       "      <td>78.100</td>\n",
       "      <td>77.52</td>\n",
       "      <td>78.91</td>\n",
       "      <td>78.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9th</th>\n",
       "      <td>78.360</td>\n",
       "      <td>78.10</td>\n",
       "      <td>78.25</td>\n",
       "      <td>78.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10th</th>\n",
       "      <td>77.340</td>\n",
       "      <td>78.39</td>\n",
       "      <td>78.09</td>\n",
       "      <td>78.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean acc_train</th>\n",
       "      <td>77.722</td>\n",
       "      <td>77.68</td>\n",
       "      <td>78.40</td>\n",
       "      <td>78.368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 90-10  80-20  70-30   60-40\n",
       "1st             77.340  78.67  77.43  77.540\n",
       "2nd             77.210  77.52  77.59  78.890\n",
       "3rd             77.720  78.53  77.10  78.690\n",
       "4th             77.850  77.95  79.24  77.540\n",
       "5th             77.980  76.08  78.58  77.930\n",
       "6th             77.980  77.67  80.56  76.580\n",
       "7th             77.340  76.37  78.25  80.230\n",
       "8th             78.100  77.52  78.91  78.890\n",
       "9th             78.360  78.10  78.25  78.890\n",
       "10th            77.340  78.39  78.09  78.500\n",
       "Mean acc_train  77.722  77.68  78.40  78.368"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_table_train_df.loc['Mean acc_train'] = acc_table_train_df.mean()\n",
    "acc_table_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "723b814e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>90-10</th>\n",
       "      <th>80-20</th>\n",
       "      <th>70-30</th>\n",
       "      <th>60-40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1st</th>\n",
       "      <td>80.000</td>\n",
       "      <td>76.270</td>\n",
       "      <td>78.410</td>\n",
       "      <td>79.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2nd</th>\n",
       "      <td>81.110</td>\n",
       "      <td>78.530</td>\n",
       "      <td>78.790</td>\n",
       "      <td>76.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3rd</th>\n",
       "      <td>77.780</td>\n",
       "      <td>78.530</td>\n",
       "      <td>80.680</td>\n",
       "      <td>76.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4th</th>\n",
       "      <td>76.670</td>\n",
       "      <td>77.970</td>\n",
       "      <td>74.620</td>\n",
       "      <td>78.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5th</th>\n",
       "      <td>78.890</td>\n",
       "      <td>83.620</td>\n",
       "      <td>75.380</td>\n",
       "      <td>77.430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6th</th>\n",
       "      <td>74.440</td>\n",
       "      <td>77.400</td>\n",
       "      <td>73.480</td>\n",
       "      <td>81.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7th</th>\n",
       "      <td>81.110</td>\n",
       "      <td>83.050</td>\n",
       "      <td>77.650</td>\n",
       "      <td>75.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8th</th>\n",
       "      <td>75.560</td>\n",
       "      <td>79.100</td>\n",
       "      <td>76.890</td>\n",
       "      <td>77.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9th</th>\n",
       "      <td>74.440</td>\n",
       "      <td>76.840</td>\n",
       "      <td>75.760</td>\n",
       "      <td>76.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10th</th>\n",
       "      <td>82.220</td>\n",
       "      <td>77.970</td>\n",
       "      <td>77.650</td>\n",
       "      <td>77.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean acc_test</th>\n",
       "      <td>78.222</td>\n",
       "      <td>78.928</td>\n",
       "      <td>76.931</td>\n",
       "      <td>77.571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                90-10   80-20   70-30   60-40\n",
       "1st            80.000  76.270  78.410  79.140\n",
       "2nd            81.110  78.530  78.790  76.290\n",
       "3rd            77.780  78.530  80.680  76.860\n",
       "4th            76.670  77.970  74.620  78.000\n",
       "5th            78.890  83.620  75.380  77.430\n",
       "6th            74.440  77.400  73.480  81.140\n",
       "7th            81.110  83.050  77.650  75.710\n",
       "8th            75.560  79.100  76.890  77.140\n",
       "9th            74.440  76.840  75.760  76.290\n",
       "10th           82.220  77.970  77.650  77.710\n",
       "Mean acc_test  78.222  78.928  76.931  77.571"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_table_test_df.loc['Mean acc_test'] = acc_table_test_df.mean()\n",
    "acc_table_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "701de631",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([acc_table_train_df.iloc[[10]], acc_table_test_df.iloc[[10]]], axis = 0).to_csv('D:/ISIBangalore/MS-QMScourse/2nd sem/Pattern Recognition/Assignment-4/accuracy table_MDC_scaled.csv', sep=',', header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f94691",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
